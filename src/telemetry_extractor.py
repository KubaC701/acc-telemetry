"""
Telemetry extraction module for detecting throttle, brake, and steering values from ROI images.
"""

import cv2
import numpy as np
from typing import Dict, Tuple


class TelemetryExtractor:
    """Extracts telemetry values from ROI images using computer vision."""
    
    @staticmethod
    def extract_bar_percentage(roi_image: np.ndarray, target_color: str = 'green', orientation: str = 'vertical') -> float:
        """
        Extract percentage value from a bar by detecting filled portion.
        Supports both horizontal and vertical bars.
        
        Args:
            roi_image: Cropped image of the bar
            target_color: 'green' for throttle, 'gray' for brake
            orientation: 'vertical' or 'horizontal'
            
        Returns:
            Percentage value (0.0 to 100.0)
        """
        if roi_image is None or roi_image.size == 0:
            return 0.0
            
        # Convert to HSV for better color detection
        hsv = cv2.cvtColor(roi_image, cv2.COLOR_BGR2HSV)
        
        if target_color == 'green':
            # Green AND Yellow color ranges (bars change color when TC activate)
            # Green range
            lower_green = np.array([35, 50, 50])
            upper_green = np.array([85, 255, 255])
            mask_green = cv2.inRange(hsv, lower_green, upper_green)
            
            # Yellow/Orange range (when TC active)
            lower_yellow = np.array([15, 100, 100])
            upper_yellow = np.array([35, 255, 255])
            mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)
            
            # Combine both masks
            mask = cv2.bitwise_or(mask_green, mask_yellow)
            
        elif target_color == 'red':
            # Red, Orange, Yellow color ranges (brake bar changes when ABS activates)
            # Red range (HSV red wraps around at 0/180)
            # ADJUSTED: Lowered V threshold from 100 → 50 to detect dim brake bars
            lower_red1 = np.array([0, 100, 50])
            upper_red1 = np.array([10, 255, 255])
            mask_red1 = cv2.inRange(hsv, lower_red1, upper_red1)

            lower_red2 = np.array([170, 100, 50])
            upper_red2 = np.array([180, 255, 255])
            mask_red2 = cv2.inRange(hsv, lower_red2, upper_red2)

            # Orange/Yellow range (when ABS active)
            # ADJUSTED: Lowered V threshold from 100 → 50 for consistency
            lower_orange = np.array([10, 100, 50])
            upper_orange = np.array([40, 255, 255])
            mask_orange = cv2.inRange(hsv, lower_orange, upper_orange)
            
            # Combine all masks
            mask = cv2.bitwise_or(cv2.bitwise_or(mask_red1, mask_red2), mask_orange)
            
        else:  # gray/white
            # Gray/white color range
            lower_bound = np.array([0, 0, 100])
            upper_bound = np.array([180, 50, 255])
            mask = cv2.inRange(hsv, lower_bound, upper_bound)
        
        height, width = mask.shape
        
        if orientation == 'vertical':
            # For vertical bars, fill goes from bottom to top
            # Sample middle columns to avoid edge artifacts
            middle_cols = mask[:, width//3:2*width//3]
            
            # Find the topmost filled pixel for each column (bar fills from bottom)
            filled_heights = []
            for col_idx in range(middle_cols.shape[1]):
                col = middle_cols[:, col_idx]
                non_zero_rows = np.where(col > 0)[0]
                if len(non_zero_rows) > 0:
                    # Calculate filled height from bottom
                    filled_height = height - non_zero_rows[0]
                    filled_heights.append(filled_height)
            
            if not filled_heights:
                return 0.0
            
            # Use median to avoid outliers
            filled_height = np.median(filled_heights)
            percentage = (filled_height / height) * 100.0
            
        else:  # horizontal
            # Sample middle rows to avoid edge artifacts
            middle_rows = mask[height//3:2*height//3, :]

            # Find the continuous filled region from the left edge
            # This handles text overlays and gaps by detecting the main bar fill
            filled_widths = []
            for row in middle_rows:
                non_zero_cols = np.where(row > 0)[0]
                if len(non_zero_cols) == 0:
                    continue

                # Find the longest continuous run starting from near the left edge
                # The bar fills from left to right, so we want the leftmost continuous region
                max_continuous_width = 0
                current_run_start = None
                current_run_length = 0

                for i, col in enumerate(non_zero_cols):
                    if current_run_start is None:
                        # Start new run
                        current_run_start = col
                        current_run_length = 1
                    elif col == non_zero_cols[i-1] + 1:
                        # Continue existing run (consecutive pixel)
                        current_run_length += 1
                    else:
                        # Gap detected - save previous run if it's the best so far
                        if current_run_length > max_continuous_width:
                            max_continuous_width = current_run_length
                        # Start new run
                        current_run_start = col
                        current_run_length = 1

                # Don't forget the last run
                if current_run_length > max_continuous_width:
                    max_continuous_width = current_run_length

                if max_continuous_width > 0:
                    filled_widths.append(max_continuous_width)

            if not filled_widths:
                return 0.0

            # Use median to avoid outliers
            filled_width = np.median(filled_widths)
            percentage = (filled_width / width) * 100.0
        
        return min(100.0, max(0.0, percentage))
    
    @staticmethod
    def extract_steering_position(roi_image: np.ndarray) -> float:
        """
        Extract steering position from the steering indicator.
        Detects white dot position on horizontal scale.
        
        Args:
            roi_image: Cropped image of the steering indicator
            
        Returns:
            Normalized steering position (-1.0 = full left, 0.0 = center, +1.0 = full right)
        """
        if roi_image is None or roi_image.size == 0:
            return 0.0
            
        # Convert to grayscale
        gray = cv2.cvtColor(roi_image, cv2.COLOR_BGR2GRAY)

        # Threshold to find bright white pixels (the dot)
        # Adjusted: 180 threshold (was 200) to catch slightly dimmer dots in different videos
        _, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)
        
        # Find contours/bright regions
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return 0.0
        
        # Filter contours to find the steering dot
        # The steering dot should be:
        # 1. Small to medium size (3-100 pixels) - steering dot is compact
        # 2. Compact (roughly square, not elongated text)
        # 3. Located in the bottom half of ROI (scale line is at bottom)
        height = roi_image.shape[0]
        width = roi_image.shape[1]

        dot_candidates = []
        for contour in contours:
            area = cv2.contourArea(contour)

            # Filter by area (steering dot is small, text is larger)
            # Adjusted: 3-100 pixels (was 5-50) to catch smaller dots in different videos
            if not (3 <= area < 100):
                continue
            
            # Get bounding box
            x, y, w, h = cv2.boundingRect(contour)
            
            # Filter by aspect ratio (dot should be roughly square, not elongated like text)
            aspect_ratio = w / h if h > 0 else 0
            if not (0.5 < aspect_ratio < 2.0):
                continue
            
            # Filter by vertical position (dot is in bottom 2/3 of ROI, text is at top)
            center_y = y + h // 2
            if center_y < height * 0.33:
                continue  # Skip things in top third (text labels)
            
            # Calculate centroid
            M = cv2.moments(contour)
            if M['m00'] == 0:
                continue
            
            cx = M['m10'] / M['m00']
            cy = M['m01'] / M['m00']
            
            dot_candidates.append({
                'contour': contour,
                'cx': cx,
                'cy': cy,
                'area': area
            })
        
        if not dot_candidates:
            # Fallback: if no good candidates, return center position
            return 0.0
        
        # Select the best candidate (largest area among filtered candidates)
        best_dot = max(dot_candidates, key=lambda d: d['area'])
        cx = best_dot['cx']
        
        # Normalize to -1.0 to +1.0 range
        normalized_position = (cx / width) * 2.0 - 1.0
        
        return max(-1.0, min(1.0, normalized_position))
    
    @staticmethod
    def extract_tc_active(roi_image: np.ndarray) -> int:
        """
        Detect if traction control (TC) is active by checking for yellow/orange color in throttle bar.
        TC activation causes the throttle bar to change from green to yellow/orange.
        
        Important: This method requires both yellow pixels AND an actual throttle bar to be present
        to avoid false positives from ABS glow bleeding into the throttle ROI.
        
        Args:
            roi_image: Cropped image of the throttle bar
            
        Returns:
            1 if TC is active (yellow/orange detected with throttle present), 0 otherwise
        """
        if roi_image is None or roi_image.size == 0:
            return 0
        
        # Convert to HSV for color detection
        hsv = cv2.cvtColor(roi_image, cv2.COLOR_BGR2HSV)
        
        # Yellow/Orange range (same as used in extract_bar_percentage for TC detection)
        lower_yellow = np.array([15, 100, 100])
        upper_yellow = np.array([35, 255, 255])
        mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)
        
        # Green range (normal throttle color)
        lower_green = np.array([35, 50, 50])
        upper_green = np.array([85, 255, 255])
        mask_green = cv2.inRange(hsv, lower_green, upper_green)
        
        # Count pixels
        yellow_pixel_count = np.count_nonzero(mask_yellow)
        green_pixel_count = np.count_nonzero(mask_green)
        total_throttle_pixels = green_pixel_count + yellow_pixel_count
        
        # TC is active if:
        # 1. Yellow pixels present (>= 50)
        # 2. Total bar pixels present (>= 150) - ensures it's a real bar, not just glow
        # This prevents false positives from ABS glow bleeding into throttle ROI
        yellow_threshold = 50
        total_pixels_threshold = 150
        
        return 1 if (yellow_pixel_count >= yellow_threshold and 
                    total_throttle_pixels >= total_pixels_threshold) else 0
    
    @staticmethod
    def extract_abs_active(roi_image: np.ndarray) -> int:
        """
        Detect if ABS is active by checking for orange/yellow color in brake bar.
        ABS activation causes the brake bar to change from red to orange/yellow.
        
        Args:
            roi_image: Cropped image of the brake bar
            
        Returns:
            1 if ABS is active (orange detected), 0 otherwise
        """
        if roi_image is None or roi_image.size == 0:
            return 0
        
        # Convert to HSV for color detection
        hsv = cv2.cvtColor(roi_image, cv2.COLOR_BGR2HSV)

        # Orange/Yellow range (same as used in extract_bar_percentage for ABS detection)
        # ADJUSTED: Lowered V threshold from 100 → 50 to detect dim ABS activation
        lower_orange = np.array([10, 100, 50])
        upper_orange = np.array([40, 255, 255])
        mask_orange = cv2.inRange(hsv, lower_orange, upper_orange)
        
        # Count orange pixels
        orange_pixel_count = np.count_nonzero(mask_orange)
        
        # Threshold: need at least 50 pixels to confirm ABS is active (avoid noise)
        min_pixels_threshold = 50
        
        return 1 if orange_pixel_count >= min_pixels_threshold else 0
    
    def extract_frame_telemetry(self, roi_dict: Dict[str, np.ndarray]) -> Dict[str, float]:
        """
        Extract all telemetry values from a frame's ROI images.
        
        Args:
            roi_dict: Dictionary with 'throttle', 'brake', 'steering' ROI images
            
        Returns:
            Dictionary with extracted values including TC and ABS activation status
        """
        return {
            'throttle': self.extract_bar_percentage(roi_dict['throttle'], 'green', 'horizontal'),
            'brake': self.extract_bar_percentage(roi_dict['brake'], 'red', 'horizontal'),
            'steering': self.extract_steering_position(roi_dict['steering']),
            'tc_active': self.extract_tc_active(roi_dict['throttle']),
            'abs_active': self.extract_abs_active(roi_dict['brake'])
        }

