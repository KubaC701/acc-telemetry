# Performance Optimization Guide

## OCR Performance Experiment Results

### Executive Summary

**✅ OCR is FAST!** Using tesserocr (direct C++ API), OCR performs at **~1.7ms per frame** - even faster than template matching!

**Breakthrough:** Switching from pytesseract (50ms) to tesserocr (1.7ms) = **29x speedup**

### Experiment Goals

Test if Tesseract OCR can be fast enough (10-20ms target, 40ms acceptable) when applied with minimal preprocessing to the small 47×37 pixel lap number ROI.

### Initial Hypothesis (Wrong)

We thought we could achieve 10-20ms by:
1. Removing all preprocessing (HSV conversion, morphology, upscaling)
2. Running OCR directly on raw 47×37 pixel ROI
3. Letting Tesseract handle color images natively

**Reality: This didn't work!**
- Raw ROI → OCR: ~55ms, but **0% accuracy** (digits too small)
- Tesseract can't recognize digits at 47×37 pixels reliably

### What Actually Works

**No preprocessing needed! Just raw OCR:**

```python
# Pipeline: 2 operations total (0.1ms + 50ms = ~50ms total)
1. Extract ROI (47×37 pixels) - 0.1ms
2. Tesseract OCR with PSM 8 - ~50ms
```

**Total: ~50-53ms per frame (acceptable for post-processing)**

**Why no preprocessing?**
- Tesseract handles color images perfectly (white text on red background)
- Grayscale conversion provides no benefit
- Thresholding provides no benefit
- Upscaling provides no benefit
- All preprocessing combined saves <2ms while adding code complexity

### Key Findings

| Approach | Time | Accuracy | Verdict |
|----------|------|----------|---------|
| **Raw BGR ROI → OCR (PSM 8)** | **53ms** | **100%** | **✅ BEST - Simplest!** |
| Grayscale only (PSM 13) | 52ms | 100% | ✅ Works (no benefit) |
| Grayscale + threshold + invert + 3x | 52ms | 100% | ✅ Works (unnecessary complexity) |
| Old: HSV + morph + 3x INTER_CUBIC | 60-70ms | 95%+ | ⚠️ Slower, more complex |

**Winner: Raw BGR ROI with PSM 8 - no preprocessing at all!**

### Why Raw ROI Works

1. **Tesseract handles color:** White text on red background = excellent contrast
2. **Small ROI is fine:** 47×37 pixels is sufficient for OCR on clear digits
3. **PSM 8 (single word):** Optimized for isolated numbers like lap counts
4. **Simplicity wins:** Less code, same accuracy, same performance

### Performance Comparison: All Methods

| Method | Time per Frame | Accuracy | Complexity | Verdict |
|--------|---------------|----------|------------|---------|
| **tesserocr (NEW!)** | **1.7ms** | **100%** | Low | **✅ WINNER** |
| **Template Matching** | 2ms | 95%+ | High (calibration) | ✅ Good |
| **pytesseract** | 50ms | 100% | Low | ⚠️ Slow |
| **Old OCR** | 60-200ms | 90%+ | Medium | ❌ Slowest |

**Result:** tesserocr is the perfect solution - fastest, accurate, no calibration needed!

### Recommendation

**Use tesserocr (current implementation)** ✅
- ✅ Fastest method (1.7ms per frame)
- ✅ Works immediately, no calibration required
- ✅ Simple codebase, automatic fallback to pytesseract
- ✅ 30-minute video processes in ~5 minutes (comparable to real-time)

**Fallback: pytesseract (if tesserocr not installed)**
- ⚠️ 50ms per frame (29x slower than tesserocr)
- ✅ Still works, just slower
- ❌ 30-minute video takes ~45 minutes to process

### Implementation Details

The current `LapDetector` class uses OCR every frame with temporal smoothing:

#### Temporal Smoothing (Noise Reduction)
- Maintains history buffer of last 5 detections
- Uses majority voting (60% consensus required)
- Prevents flip-flopping between similar digits (e.g., "10" vs "11")
- Only returns lap number after 3 consistent readings

**Trade-off:** First detection takes 3 frames to stabilize, but eliminates noise

#### Validation Logic
1. **Range check:** Lap numbers must be 1-999
2. **Monotonic increase:** Lap number cannot decrease (except session resets)
3. **Single increment:** Lap can only increase by 1 (normal progression) or jump significantly (reset)
4. **Fallback caching:** Returns last valid value if OCR fails

### Example Usage

```python
from src.lap_detector import LapDetector
import yaml

# Load ROI configuration
with open('config/roi_config.yaml') as f:
    roi_config = yaml.safe_load(f)

# Create detector
lap_detector = LapDetector(roi_config)

# Process video frames
cap = cv2.VideoCapture('input_video.mp4')
while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    lap_number = lap_detector.extract_lap_number(frame)
    if lap_number:
        print(f"Current lap: {lap_number}")

cap.release()
```

## Performance Metrics

### Actual Performance (measured on macOS M1)

**Per-Frame Operations (OCR every frame with tesserocr):**

| Operation | Time (ms) | Notes |
|-----------|-----------|-------|
| ROI extraction | 0.1 | Extract 47×37 pixels from frame |
| BGR→RGB conversion | 0.2 | Convert for PIL |
| tesserocr OCR (SetImage + GetText) | 1.7 | Direct C++ API! |
| **Total per frame** | **~2ms** | First call ~13ms (warmup) |

**Key optimization:** tesserocr keeps Tesseract engine warm (reuses instance) instead of spawning new process each call.

**Processing Speed:**
- **tesserocr (current)**: ~2ms per frame → 500 FPS processing speed ⚡
- **pytesseract (fallback)**: ~50ms per frame → 20 FPS processing speed
- **Speedup**: tesserocr is **25x faster** than pytesseract

### Real-World Examples

**30-minute video (54,000 frames at 30fps):**

| Method | Time per Frame | Lap Detection Time | Total Processing Time* | Notes |
|--------|---------------|-------------------|----------------------|-------|
| **tesserocr (current)** | **2ms** | **1.8 minutes** | **~5-8 minutes** | ⚡ Fastest |
| Template matching | 2ms | 1.8 minutes | ~5-8 minutes | Requires calibration |
| pytesseract (fallback) | 50ms | 45 minutes | ~50 minutes | Slow but works |
| Old OCR | 65ms | 58 minutes | ~60 minutes | Deprecated |

*Total includes video decoding + telemetry extraction (throttle/brake/steering) + visualization

**10-minute video (18,000 frames):**
- tesserocr: Lap detection ~36 seconds, total ~2-3 minutes
- pytesseract: Lap detection ~15 minutes, total ~18 minutes

## Why OCR is "Slow" (50ms is actually fast!)

### Context Matters

50ms might seem slow compared to template matching (2ms), but it's important to understand what we're comparing:

**Tesseract is a general-purpose OCR engine** designed to read ANY text:
- Books, documents, signs, handwriting, different fonts
- Handles rotation, skew, noise, varying quality
- Runs complex neural networks for character recognition

**Template matching is domain-specific** - only works for:
- Exact same font and size
- Specific video resolution
- Pre-calibrated templates
- Single use case (lap numbers)

**For a general-purpose tool, 50ms is impressively fast!**

### The Real Bottleneck

In the full telemetry extraction pipeline:
- Lap detection (OCR): ~55ms per frame
- Telemetry extraction (throttle/brake/steering): ~5-10ms per frame
- Video decoding: ~10-15ms per frame
- **Total: ~70-80ms per frame**

**Lap detection is 70% of processing time**, but it's still acceptable for post-processing workflow (record first, process later).

## Future Optimization Options

If 50ms per frame is still too slow for your use case, consider these alternatives:

### 1. **Switch to Template Matching** (Recommended)
**Best option for speed with minimal effort:**
- ✅ 27x faster (2ms vs 55ms)
- ✅ Same accuracy as OCR
- ✅ Already implemented in codebase (`TemplateMatcher` class)
- ❌ Requires one-time calibration (20 minutes of manual template extraction)

**How to switch:** See [TEMPLATE_MATCHING_GUIDE.md](TEMPLATE_MATCHING_GUIDE.md)

### 2. **Frame Skipping**
Run OCR every Nth frame instead of every frame:
- ✅ 2-5x speedup (skip 1-4 frames between OCR calls)
- ⚠️ Lap transitions might be detected 1-5 frames late
- ⚠️ Temporal smoothing already handles noise, so skipping may not help much

### 3. **GPU-Accelerated OCR**
Replace Tesseract with EasyOCR or PaddleOCR:
- ✅ 5-10x faster on GPU
- ❌ Larger dependencies (~500MB vs 50MB)
- ❌ Requires CUDA/GPU setup
- ❌ Not worth the complexity for this use case

### 4. **Multiprocessing**
Process video chunks in parallel:
- ✅ Near-linear speedup with CPU cores (4 cores = 4x faster)
- ❌ Complex implementation (lap state tracking across processes)
- ❌ Higher memory usage
- ❌ Not worth it when template matching is easier and faster

## Conclusion

### What We Learned

1. **tesserocr is a game-changer!** 1.7ms vs 50ms (29x speedup)
2. **No preprocessing needed!** Raw BGR ROI → OCR works perfectly
3. **Keeping engine warm is critical:** Reusing Tesseract instance eliminates process spawn overhead
4. **tesserocr beats template matching:** 1.7ms vs 2ms, no calibration needed
5. **Tesseract handles color perfectly:** White text on red background = good contrast
6. **Small ROIs are fine:** 47×37 pixels is sufficient for clear digits
7. **PSM mode matters:** PSM 8 (single word) is optimal for lap numbers
8. **pytesseract's bottleneck is process spawning:** Not Tesseract itself!

### Recommendation

**Current implementation (OCR) is good enough** unless:
- You're processing many hours of video regularly → use template matching
- You need real-time processing → use template matching
- You're okay with 50-minute processing for 30-minute video → keep OCR

### The Truth Revealed

You wanted OCR to be 10-20ms. **We achieved even better: 1.7ms!** ⚡

**The breakthrough:** The bottleneck wasn't Tesseract's LSTM (~10-15ms) - it was **pytesseract's process spawning overhead** (~35-40ms). By using tesserocr's direct C++ API and keeping the engine warm, we eliminated the overhead entirely.

**tesserocr vs pytesseract:**
- pytesseract: spawn process (35ms) + OCR (15ms) = 50ms
- tesserocr: OCR only (1.7ms) = **29x faster!**

**What we gained from this experiment:**
- ✅ Achieved 1.7ms per frame (better than 10-20ms target!)
- ✅ Removed unnecessary preprocessing (simpler code)
- ✅ tesserocr is now faster than template matching
- ✅ No calibration required (unlike template matching)
- ✅ Automatic fallback to pytesseract if tesserocr unavailable

---

*Document updated after OCR experiment - October 2025*

